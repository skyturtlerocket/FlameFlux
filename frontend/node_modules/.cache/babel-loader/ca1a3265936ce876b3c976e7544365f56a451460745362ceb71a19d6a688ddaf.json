{"ast":null,"code":"// API calls to Flask backend\n\nexport const fetchRealTimeFireData = async () => {\n  try {\n    console.log(\"Fetching real-time fire data from Flask backend...\");\n    const response = await fetch('http://localhost:5000/api/fires', {\n      method: 'GET',\n      headers: {\n        'Accept': 'application/json',\n        'Content-Type': 'application/json'\n      }\n    });\n    if (!response.ok) {\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n    const data = await response.json();\n    console.log(`Received ${data.total || 0} fires from backend`);\n    return data.fires || [];\n  } catch (error) {\n    console.error('Failed to fetch fire data from backend:', error);\n    throw error;\n  }\n};\n\n// Mock prediction service - replace with actual model API call\nexport const fetchPrediction = async (fireId, fireData) => {\n  if (!fireData) {\n    console.error('No fire data provided');\n    return null;\n  }\n\n  // Simulate API delay\n  await new Promise(resolve => setTimeout(resolve, 2000));\n\n  // Mock data - replace with actual model prediction\n  const mockPrediction = {\n    fireId: fireId,\n    predictionDate: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString(),\n    estimatedSize: fireData.size * (1.2 + Math.random() * 0.8),\n    confidence: Math.floor(Math.random() * 20) + 75,\n    riskLevel: Math.random() > 0.5 ? 'High' : 'Critical',\n    perimeter: [[fireData.lat + 0.01, fireData.lng + 0.01], [fireData.lat + 0.02, fireData.lng + 0.005], [fireData.lat + 0.015, fireData.lng - 0.01], [fireData.lat - 0.005, fireData.lng - 0.015], [fireData.lat - 0.01, fireData.lng + 0.005]]\n  };\n  return mockPrediction;\n};","map":{"version":3,"names":["fetchRealTimeFireData","console","log","response","fetch","method","headers","ok","Error","status","data","json","total","fires","error","fetchPrediction","fireId","fireData","Promise","resolve","setTimeout","mockPrediction","predictionDate","Date","now","toISOString","estimatedSize","size","Math","random","confidence","floor","riskLevel","perimeter","lat","lng"],"sources":["/Users/timothyha/firecast/frontend/src/services/fireApi.js"],"sourcesContent":["// API calls to Flask backend\n\nexport const fetchRealTimeFireData = async () => {\n    try {\n      console.log(\"Fetching real-time fire data from Flask backend...\");\n      \n      const response = await fetch('http://localhost:5000/api/fires', {\n        method: 'GET',\n        headers: {\n          'Accept': 'application/json',\n          'Content-Type': 'application/json'\n        }\n      });\n      \n      if (!response.ok) {\n        throw new Error(`HTTP error! status: ${response.status}`);\n      }\n      \n      const data = await response.json();\n      \n      console.log(`Received ${data.total || 0} fires from backend`);\n      \n      return data.fires || [];\n    } catch (error) {\n      console.error('Failed to fetch fire data from backend:', error);\n      throw error;\n    }\n  };\n  \n  // Mock prediction service - replace with actual model API call\n  export const fetchPrediction = async (fireId, fireData) => {\n    if (!fireData) {\n      console.error('No fire data provided');\n      return null;\n    }\n    \n    // Simulate API delay\n    await new Promise(resolve => setTimeout(resolve, 2000));\n    \n    // Mock data - replace with actual model prediction\n    const mockPrediction = {\n      fireId: fireId,\n      predictionDate: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString(),\n      estimatedSize: fireData.size * (1.2 + Math.random() * 0.8),\n      confidence: Math.floor(Math.random() * 20) + 75,\n      riskLevel: Math.random() > 0.5 ? 'High' : 'Critical',\n      perimeter: [\n        [fireData.lat + 0.01, fireData.lng + 0.01],\n        [fireData.lat + 0.02, fireData.lng + 0.005],\n        [fireData.lat + 0.015, fireData.lng - 0.01],\n        [fireData.lat - 0.005, fireData.lng - 0.015],\n        [fireData.lat - 0.01, fireData.lng + 0.005]\n      ]\n    };\n    \n    return mockPrediction;\n  };"],"mappings":"AAAA;;AAEA,OAAO,MAAMA,qBAAqB,GAAG,MAAAA,CAAA,KAAY;EAC7C,IAAI;IACFC,OAAO,CAACC,GAAG,CAAC,oDAAoD,CAAC;IAEjE,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAAC,iCAAiC,EAAE;MAC9DC,MAAM,EAAE,KAAK;MACbC,OAAO,EAAE;QACP,QAAQ,EAAE,kBAAkB;QAC5B,cAAc,EAAE;MAClB;IACF,CAAC,CAAC;IAEF,IAAI,CAACH,QAAQ,CAACI,EAAE,EAAE;MAChB,MAAM,IAAIC,KAAK,CAAC,uBAAuBL,QAAQ,CAACM,MAAM,EAAE,CAAC;IAC3D;IAEA,MAAMC,IAAI,GAAG,MAAMP,QAAQ,CAACQ,IAAI,CAAC,CAAC;IAElCV,OAAO,CAACC,GAAG,CAAC,YAAYQ,IAAI,CAACE,KAAK,IAAI,CAAC,qBAAqB,CAAC;IAE7D,OAAOF,IAAI,CAACG,KAAK,IAAI,EAAE;EACzB,CAAC,CAAC,OAAOC,KAAK,EAAE;IACdb,OAAO,CAACa,KAAK,CAAC,yCAAyC,EAAEA,KAAK,CAAC;IAC/D,MAAMA,KAAK;EACb;AACF,CAAC;;AAED;AACA,OAAO,MAAMC,eAAe,GAAG,MAAAA,CAAOC,MAAM,EAAEC,QAAQ,KAAK;EACzD,IAAI,CAACA,QAAQ,EAAE;IACbhB,OAAO,CAACa,KAAK,CAAC,uBAAuB,CAAC;IACtC,OAAO,IAAI;EACb;;EAEA;EACA,MAAM,IAAII,OAAO,CAACC,OAAO,IAAIC,UAAU,CAACD,OAAO,EAAE,IAAI,CAAC,CAAC;;EAEvD;EACA,MAAME,cAAc,GAAG;IACrBL,MAAM,EAAEA,MAAM;IACdM,cAAc,EAAE,IAAIC,IAAI,CAACA,IAAI,CAACC,GAAG,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,IAAI,CAAC,CAACC,WAAW,CAAC,CAAC;IACxEC,aAAa,EAAET,QAAQ,CAACU,IAAI,IAAI,GAAG,GAAGC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,GAAG,CAAC;IAC1DC,UAAU,EAAEF,IAAI,CAACG,KAAK,CAACH,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE;IAC/CG,SAAS,EAAEJ,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,GAAG,GAAG,MAAM,GAAG,UAAU;IACpDI,SAAS,EAAE,CACT,CAAChB,QAAQ,CAACiB,GAAG,GAAG,IAAI,EAAEjB,QAAQ,CAACkB,GAAG,GAAG,IAAI,CAAC,EAC1C,CAAClB,QAAQ,CAACiB,GAAG,GAAG,IAAI,EAAEjB,QAAQ,CAACkB,GAAG,GAAG,KAAK,CAAC,EAC3C,CAAClB,QAAQ,CAACiB,GAAG,GAAG,KAAK,EAAEjB,QAAQ,CAACkB,GAAG,GAAG,IAAI,CAAC,EAC3C,CAAClB,QAAQ,CAACiB,GAAG,GAAG,KAAK,EAAEjB,QAAQ,CAACkB,GAAG,GAAG,KAAK,CAAC,EAC5C,CAAClB,QAAQ,CAACiB,GAAG,GAAG,IAAI,EAAEjB,QAAQ,CAACkB,GAAG,GAAG,KAAK,CAAC;EAE/C,CAAC;EAED,OAAOd,cAAc;AACvB,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}